{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "128\n",
      "64\n",
      "32\n",
      "16\n",
      "8\n",
      "UNet3D(\n",
      "  (downsample): ModuleList(\n",
      "    (0): UNetConvBlock3D(\n",
      "      (conv1): Conv3d(7, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (1): UNetConvBlock3D(\n",
      "      (conv1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (2): UNetConvBlock3D(\n",
      "      (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (3): UNetConvBlock3D(\n",
      "      (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (4): UNetConvBlock3D(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (upsample): ModuleList(\n",
      "    (0): UNetUpBlock3D(\n",
      "      (up): ConvTranspose3d(128, 64, kernel_size=(3, 4, 4), stride=(4, 4, 4))\n",
      "      (conv_block): UNetConvBlock3D(\n",
      "        (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): UNetUpBlock3D(\n",
      "      (up): ConvTranspose3d(64, 32, kernel_size=(3, 4, 4), stride=(4, 4, 4))\n",
      "      (conv_block): UNetConvBlock3D(\n",
      "        (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): UNetUpBlock3D(\n",
      "      (up): ConvTranspose3d(32, 16, kernel_size=(3, 4, 4), stride=(4, 4, 4))\n",
      "      (conv_block): UNetConvBlock3D(\n",
      "        (conv1): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): UNetUpBlock3D(\n",
      "      (up): ConvTranspose3d(16, 8, kernel_size=(3, 4, 4), stride=(4, 4, 4))\n",
      "      (conv_block): UNetConvBlock3D(\n",
      "        (conv1): Conv3d(16, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): UNetUpBlock3D(\n",
      "      (up): ConvTranspose3d(8, 9, kernel_size=(3, 4, 4), stride=(4, 4, 4))\n",
      "      (conv_block): UNetConvBlock3D(\n",
      "        (conv1): Conv3d(8, 9, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv3d(9, 9, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "1855960\n",
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "128\n",
      "64\n",
      "32\n",
      "16\n",
      "8\n",
      "input torch.Size([4, 7, 3, 256, 256])\n",
      "down torch.Size([4, 8, 3, 256, 256])\n",
      "skip_connection 0 torch.Size([4, 8, 3, 256, 256])\n",
      "down torch.Size([4, 16, 3, 64, 64])\n",
      "skip_connection 1 torch.Size([4, 16, 3, 64, 64])\n",
      "down torch.Size([4, 32, 3, 16, 16])\n",
      "skip_connection 2 torch.Size([4, 32, 3, 16, 16])\n",
      "down torch.Size([4, 64, 3, 4, 4])\n",
      "skip_connection 3 torch.Size([4, 64, 3, 4, 4])\n",
      "down torch.Size([4, 128, 3, 1, 1])\n",
      "skip_connection 4 torch.Size([4, 128, 3, 1, 1])\n",
      "[torch.Size([4, 8, 3, 256, 256]), torch.Size([4, 16, 3, 64, 64]), torch.Size([4, 32, 3, 16, 16]), torch.Size([4, 64, 3, 4, 4])]\n",
      "torch.Size([4, 128, 3, 1, 1]) torch.Size([4, 64, 3, 4, 4])\n",
      "torch.Size([4, 64, 11, 4, 4]) torch.Size([4, 64, 3, 4, 4])\n",
      "torch.Size([4, 64, 14, 4, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 128, 3, 3, 3], expected input[4, 64, 14, 4, 4] to have 128 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ccae144e6968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;31m#     train(model, loader, optimiser, EPOCHS, IN_FRAMES, OUT_FRAMES, DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ccae144e6968>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIN_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_FRAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ccae144e6968>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, skip_connections)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_connections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"up\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ccae144e6968>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skip_connection)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ccae144e6968>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    479\u001b[0m                             self.dilation, self.groups)\n\u001b[1;32m    480\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 481\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 128, 3, 3, 3], expected input[4, 64, 14, 4, 4] to have 128 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as t\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler, BatchSampler\n",
    "from dataset import FkDataset, Simulation\n",
    "import fk\n",
    "import numpy as np\n",
    "from flows import MADE\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def log(*m, **kwargs):\n",
    "    if DEBUG:\n",
    "        print(*m, **kwargs)\n",
    "        \n",
    "def log_progress(epoch, batch_number, n_batches, loss):\n",
    "    s = f\"Epoch: {epoch} \\t Batch: {batch_number}/{n_batches} \\t\"\n",
    "    s += \"\\t\".join([\"{}_loss: {:.4f}\".format(k, v) for k, v in loss.items()])\n",
    "    print(s, end=\"\\r\")\n",
    "    return\n",
    "\n",
    "def plot_progress(epoch, x_hat, x, loss, **kwargs):\n",
    "    fk.plot.show(x_hat.detach().cpu().numpy(), vmin=None, vmax=None)\n",
    "    fk.plot.show(x.detach().cpu().numpy(), vmin=None, vmax=None)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def gradient_loss(gen_frames, gt_frames):\n",
    "    def gradient(x):\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        left = x\n",
    "        right = torch.nn.functional.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = torch.nn.functional.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        dx, dy = right - left, bottom - top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return torch.sqrt(dx.pow(2) + dy.pow(2))\n",
    "\n",
    "    grad_pred = gradient(gen_frames)\n",
    "    grad_truth = gradient(gt_frames)\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return torch.nn.functional.mse_loss(grad_pred, grad_truth, reduction=\"sum\")\n",
    "\n",
    "class Downsample:\n",
    "    def __init__(self, size, mode=\"bicubic\"):\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.interpolate(x, self.size)\n",
    "    \n",
    "class UNetConvBlock3D(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, padding):\n",
    "        super(UNetConvBlock3D, self).__init__()\n",
    "\n",
    "        # add convolution 1\n",
    "        self.add_module(\"conv1\",\n",
    "                        nn.Conv3d(in_channels=in_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu1\", nn.ReLU())\n",
    "\n",
    "        # add convolution 2\n",
    "        self.add_module(\"conv2\",\n",
    "                        nn.Conv3d(in_channels=out_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu2\", nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "class UNetUpBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding):\n",
    "        super(UNetUpBlock3D, self).__init__()\n",
    "\n",
    "        # upsample\n",
    "        self.up = nn.ConvTranspose3d(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     kernel_size=(3, 4, 4),\n",
    "                                     stride=4)\n",
    "\n",
    "        # add convolutions block\n",
    "        self.conv_block = UNetConvBlock3D(in_channels=in_channels,\n",
    "                                        out_channels=out_channels,\n",
    "                                        padding=padding)\n",
    "\n",
    "    def forward(self, x, skip_connection):\n",
    "        log(x.shape, skip_connection.shape)\n",
    "        up = self.up(x)\n",
    "        log(up.shape, skip_connection.shape)\n",
    "        out = torch.cat([up, skip_connection], 2)\n",
    "        log(out.shape)\n",
    "        out = self.conv_block(out)\n",
    "        log(out.shape)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, filters, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        depth = len(filters)\n",
    "        if (in_channels == 1 and out_channels == 0):\n",
    "            in_channels = 3\n",
    "            out_channels = 3\n",
    "        \n",
    "        # downsampling\n",
    "        self.downsample = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            log(filters[i])\n",
    "            self.downsample.append(UNetConvBlock3D(in_channels=in_channels,\n",
    "                                                 out_channels=filters[i],\n",
    "                                                 padding=1))\n",
    "            in_channels = filters[i]\n",
    "        \n",
    "        # upsample\n",
    "        self.upsample = nn.ModuleList()\n",
    "        out_filter = [out_channels] + filters\n",
    "        for i in reversed(range(depth)):\n",
    "            log(filters[i])\n",
    "            self.upsample.append(UNetUpBlock3D(in_channels=in_channels,\n",
    "                                             out_channels=out_filter[i],\n",
    "                                             padding=1))\n",
    "            in_channels = out_filter[i]\n",
    "            \n",
    "        self.output = nn.Conv2d(in_channels, out_channels, 1, 1)\n",
    "        return\n",
    "    \n",
    "    def get_loss(self, u, sum_log_abs_det_jacobians, y_hat, y):\n",
    "        mse =  torch.sqrt(F.mse_loss(y_hat, y, reduction=\"sum\"))\n",
    "        grad = torch.sqrt(gradient_loss(y_hat, y))\n",
    "        nf = torch.sum(self.propagator.base_dist.log_prob(u) + sum_log_abs_det_jacobians, dim=1).sum()\n",
    "        return {\"mse\": mse, \"grad\": grad, \"nf\": nf}\n",
    "    \n",
    "    def encode(self, X):\n",
    "        log(\"input\", X.shape)\n",
    "        skip_connections = []\n",
    "        z = X\n",
    "        for i, down in enumerate(self.downsample):\n",
    "            z = down(z)\n",
    "            log(\"down\", z.shape)\n",
    "            log(\"skip_connection {}\".format(i), z.shape)\n",
    "            if i != len(self.downsample) - 1:\n",
    "                skip_connections.append(z)\n",
    "                z = F.max_pool3d(z, (1, 4, 4))\n",
    "        return z, skip_connections\n",
    "    \n",
    "    def decode(self, z, skip_connections):\n",
    "        print([s.shape for s in skip_connections])\n",
    "        for i, up in enumerate(self.upsample):\n",
    "            y_hat = up(z, skip_connections[-i - 1])\n",
    "            log(\"up\", y_hat.shape)\n",
    "        y_hat = self.output(y_hat)\n",
    "        log(\"output\", y_hat.shape)\n",
    "        return y_hat\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z, skip_connections = self.encode(X)\n",
    "        y_hat = self.decode(z, skip_connections)\n",
    "        return y_hat, self.get_loss(u, jacobian, y_hat, X)\n",
    "    \n",
    "    def parameters_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    c = torch.stack(batch)\n",
    "    log(\"Loading {}\".format(hash(c)))\n",
    "    return c\n",
    "\n",
    "def train(model, loader, optimiser, epochs, frames_in, frames_out, device):\n",
    "    for e in range(epochs):\n",
    "        for b, y in enumerate(loader):\n",
    "            y = torch.ra\n",
    "            log(y.shape)\n",
    "            y = y.to(device)\n",
    "            y_in = y[:, :frames_in]\n",
    "            y_out = y[:, frames_in:]\n",
    "            log(y_in.shape)\n",
    "            log(y_out.shape)\n",
    "            model = model.to(device)\n",
    "            z, skip_connections = model.encode(y_in)\n",
    "            y_hat = model.decode(z, skip_connections)\n",
    "            \n",
    "            rec_loss = torch.sqrt(F.mse_loss(y_hat, y_out, reduction=\"sum\"))            \n",
    "            loss = rec_loss# + nf_loss\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # log\n",
    "            log_progress(e, b, len(loader), {\"loss\": loss})\n",
    "            idx = random.randint(0, len(y_hat) - 1)\n",
    "            plot_progress(e, y_hat[idx], y[idx], loss)\n",
    "\n",
    "def test():\n",
    "    y_in = torch.randn(BATCH_SIZE, IN_FRAMES, 3, INPUT_SIZE, INPUT_SIZE, device=DEVICE)\n",
    "    y_out = torch.randn(BATCH_SIZE, OUT_FRAMES, 3, INPUT_SIZE, INPUT_SIZE, device=DEVICE)\n",
    "    model = UNet3D([8, 16, 32, 64, 128], IN_FRAMES, OUT_FRAMES).to(DEVICE)\n",
    "    z, skip_connections = model.encode(y_in)\n",
    "    y_hat = model.decode(z, skip_connections)\n",
    "    loss = torch.sqrt(F.mse_loss(y_hat, y_out, reduction=\"sum\"))\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ## HYPERPARAMS\n",
    "    ROOT = \"/media/SSD1/epignatelli/train_dev_set/\"\n",
    "    EPOCHS = 100000\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    INPUT_SIZE = 256\n",
    "    HIDDEN_SIZE = 2048\n",
    "    BATCH_SIZE = 4\n",
    "    IN_FRAMES = 7\n",
    "    OUT_FRAMES = 9\n",
    "    DEBUG = True\n",
    "    \n",
    "    model = UNet3D([8, 16, 32, 64, 128], IN_FRAMES, OUT_FRAMES).to(DEVICE)\n",
    "    log(model)\n",
    "    log(model.parameters_count())\n",
    "    fkset = FkDataset(ROOT, IN_FRAMES, OUT_FRAMES, 1, transforms=t.Compose([Downsample((INPUT_SIZE, INPUT_SIZE))]), squeeze=True)\n",
    "    loader = DataLoader(fkset, num_workers=0, collate_fn=collate_fn, batch_size=BATCH_SIZE, drop_last=True)\n",
    "    optimiser = torch.optim.Adam(model.parameters())\n",
    "#     train(model, loader, optimiser, EPOCHS, IN_FRAMES, OUT_FRAMES, DEVICE)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
