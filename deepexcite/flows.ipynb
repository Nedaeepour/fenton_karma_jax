{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as td\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bijector(nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def forward(self, u):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def inverse(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abstractmethod        \n",
    "    def inverse_log_det_jacobian(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class TransformedDistribution(nn.Module, ABC):\n",
    "    def __init__(self, base_distribution, bijector):\n",
    "        super(TransformedDistribution, self).__init__()\n",
    "        self.base_distribution = base_distribution\n",
    "        self.bijector = bijector\n",
    "        return\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, u):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "class Flow(nn.Sequential):\n",
    "    def forward(self, x, y):\n",
    "        acc_log_abs_det_jacobian = 0\n",
    "        for bijector in self:\n",
    "            x, log_abs_det_jacobian = bijector(x, y)\n",
    "            acc_log_abs_det_jacobian += log_abs_det_jacobian\n",
    "        return x, acc_log_abs_det_jacobian\n",
    "\n",
    "    def inverse(self, u, y):\n",
    "        acc_log_abs_det_jacobian = 0\n",
    "        for module in reversed(self):\n",
    "            u, log_abs_det_jacobian = module.inverse(u, y)\n",
    "            acc_log_abs_det_jacobian += log_abs_det_jacobian\n",
    "        return u, acc_log_abs_det_jacobian\n",
    "    \n",
    "    def log_prob(self, x, y=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains the most commonly used bijectors, i.e. parameterised distribution transformations\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Affine(Bijector, nn.Linear):\n",
    "    \"\"\"\n",
    "    Scales and shifts into a standard multivariate Gaussian\n",
    "    \"\"\"\n",
    "    def forward(self, u, y=None):\n",
    "        x = F.linear(u, self.weight, self.bias)\n",
    "        if y is not None:\n",
    "            x += F.linear(y, self.weight, self.bias)\n",
    "        return x\n",
    "    \n",
    "    def inverse(self, x):\n",
    "        return \n",
    "    \n",
    "    def inverse_log_det_jacobian(self, x):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoregressiveFLow(Flow):\n",
    "    def __init__(self, input_dim, hidden_dim, n_layers):\n",
    "        self.base_distribution = td.Normal(torch.tensor(0.), torch.tensor(1.))\n",
    "        bijectors = [Affine(input_dim, hidden_dim) for _ in range(n_layers)]\n",
    "        super(MaskedAutoregressiveFLow, self).__init__(*bijectors)\n",
    "        return\n",
    "    \n",
    "    def log_prob(self, x, y=None):\n",
    "        u, acc_log_abs_det_jacobians = self.forward(x, y)\n",
    "        return torch.sum(self.base_distribution.log_prob(u) + acc_log_abs_det_jacobians, dim=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf = MaskedAutoregressiveFLow(32, 32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d81822acd6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2c3a6b6c09d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0macc_log_abs_det_jacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbijector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_abs_det_jacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbijector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0macc_log_abs_det_jacobian\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlog_abs_det_jacobian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_log_abs_det_jacobian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "maf(torch.randn(32, 32), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
