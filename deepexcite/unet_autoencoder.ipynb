{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 4, 3, 3], expected input[9, 3, 1200, 1200] to have 4 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce19bb8afd5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIN_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUT_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ce19bb8afd5e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimiser, epochs, frames_in, frames_out, device)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce19bb8afd5e>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"down\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ce19bb8afd5e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fk/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 4, 3, 3], expected input[9, 3, 1200, 1200] to have 4 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# import math\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as t\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler, BatchSampler\n",
    "from dataset import FkDataset, Simulation\n",
    "import fk\n",
    "import numpy as np\n",
    "from flows import MADE\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def log(*m, **kwargs):\n",
    "    if DEBUG:\n",
    "        print(*m, **kwargs)\n",
    "        \n",
    "def log_progress(epoch, batch_number, n_batches, loss):\n",
    "    s = f\"Epoch: {epoch} \\t Batch: {batch_number}/{n_batches} \\t\"\n",
    "    s += \"\\t\".join([\"{}_loss: {:.4f}\".format(k, v) for k, v in loss.items()])\n",
    "    print(s, end=\"\\r\")\n",
    "    return\n",
    "\n",
    "def plot_progress(epoch, x_hat, x, loss, **kwargs):\n",
    "    fk.plot.show(x_hat.detach().cpu().numpy(), vmin=None, vmax=None)\n",
    "    fk.plot.show(x.detach().cpu().numpy(), vmin=None, vmax=None)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def gradient_loss(gen_frames, gt_frames):\n",
    "    def gradient(x):\n",
    "        # idea from tf.image.image_gradients(image)\n",
    "        # https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/image_ops_impl.py#L3441-L3512\n",
    "        # x: (b,c,h,w), float32 or float64\n",
    "        # dx, dy: (b,c,h,w)\n",
    "\n",
    "        h_x = x.size()[-2]\n",
    "        w_x = x.size()[-1]\n",
    "        # gradient step=1\n",
    "        left = x\n",
    "        right = torch.nn.functional.pad(x, [0, 1, 0, 0])[:, :, :, 1:]\n",
    "        top = x\n",
    "        bottom = torch.nn.functional.pad(x, [0, 0, 0, 1])[:, :, 1:, :]\n",
    "\n",
    "        # dx, dy = torch.abs(right - left), torch.abs(bottom - top)\n",
    "        dx, dy = right - left, bottom - top\n",
    "        # dx will always have zeros in the last column, right-left\n",
    "        # dy will always have zeros in the last row,    bottom-top\n",
    "        dx[:, :, :, -1] = 0\n",
    "        dy[:, :, -1, :] = 0\n",
    "\n",
    "        return torch.sqrt(dx.pow(2) + dy.pow(2))\n",
    "\n",
    "    # gradient\n",
    "    grad_pred = gradient(gen_frames)\n",
    "    grad_truth = gradient(gt_frames)\n",
    "\n",
    "    # condense into one tensor and avg\n",
    "    return torch.nn.functional.mse_loss(grad_pred, grad_truth, reduction=\"sum\")\n",
    "\n",
    "class Downsample:\n",
    "    def __init__(self, size, mode=\"bicubic\"):\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.interpolate(x, self.size)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, size=256, h=None, w=None):\n",
    "        self.size = size\n",
    "        self.h = h if h is not None else 1\n",
    "        self.w = w if w is not None else 1\n",
    "        super(Unflatten, self).__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), self.size, self.w, self.h)\n",
    "\n",
    "class Elu(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return nn.functional.elu(x)\n",
    "    \n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        # add convolution 1\n",
    "        self.add_module(\"conv1\",\n",
    "                        nn.Conv2d(in_channels=in_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu1\", nn.ReLU())\n",
    "\n",
    "        # add convolution 2\n",
    "        self.add_module(\"conv2\",\n",
    "                        nn.Conv2d(in_channels=out_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu2\", nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "class ConvTransposeBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding):\n",
    "        super(ConvTransposeBlock, self).__init__()\n",
    "\n",
    "        # upsample\n",
    "        self.up = nn.ConvTranspose2d(in_channels=in_channels,\n",
    "                                     out_channels=out_channels,\n",
    "                                     kernel_size=4,\n",
    "                                     stride=4)\n",
    "\n",
    "        # add convolutions block\n",
    "        self.conv_block = ConvBlock(in_channels=in_channels,\n",
    "                                        out_channels=out_channels,\n",
    "                                        padding=padding)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, skip_connection):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(skip_connection, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, filters, hidden_size, input_size, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        depth = len(filters)\n",
    "        if (in_channels == 1 and out_channels == 0):\n",
    "            in_channels = 3\n",
    "            out_channels = 3\n",
    "        \n",
    "        # downsampling\n",
    "        self.downsample = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            log(filters[i])\n",
    "            self.downsample.append(UNetConvBlock(in_channels=in_channels,\n",
    "                                                 out_channels=filters[i],\n",
    "                                                 padding=1))\n",
    "            in_channels = filters[i]\n",
    "        \n",
    "        # latent\n",
    "        self.latent_cont = nn.Conv2d(in_channels, in_channels, 1, 1)\n",
    "        self.flatten = Flatten()\n",
    "        self.latent_in = nn.Linear(input_size // 2, hidden_size)\n",
    "        self.latent_out = nn.Linear(hidden_size, input_size // 2)\n",
    "        self.unflatten = Unflatten(input_size // 2 , 1, 1)\n",
    "        \n",
    "#         # propagator\n",
    "        self.propagator = MADE(hidden_size, hidden_size, 5)\n",
    "        \n",
    "        # upsample\n",
    "        self.upsample = nn.ModuleList()\n",
    "        out_filter = [out_channels] + filters\n",
    "        for i in reversed(range(1, depth)):\n",
    "            log(filters[i])\n",
    "            self.upsample.append(UNetUpBlock(in_channels=in_channels,\n",
    "                                             out_channels=out_filter[i],\n",
    "                                             padding=1))\n",
    "            in_channels = out_filter[i]\n",
    "            \n",
    "        self.output = nn.Conv2d(in_channels, out_channels, 1, 1)\n",
    "        return\n",
    "    \n",
    "    def get_loss(self, u, sum_log_abs_det_jacobians, y_hat, y):\n",
    "        mse =  torch.sqrt(F.mse_loss(y_hat, y, reduction=\"sum\"))\n",
    "        grad = torch.sqrt(gradient_loss(y_hat, y))\n",
    "        nf = torch.sum(self.propagator.base_dist.log_prob(u) + sum_log_abs_det_jacobians, dim=1).sum()\n",
    "        return {\"mse\": mse, \"grad\": grad, \"nf\": nf}\n",
    "    \n",
    "    def encode(self, X):\n",
    "        log(\"input\", X.shape)\n",
    "        skip_connections = []\n",
    "        z = X\n",
    "        for i, down in enumerate(self.downsample):\n",
    "            z = down(z)\n",
    "            log(\"down\", z.shape)\n",
    "            if i != len(self.downsample) - 1:\n",
    "                skip_connections.append(z)\n",
    "                z = F.max_pool2d(z, 4)\n",
    "                \n",
    "        z = self.flatten(z)\n",
    "        log(\"flatten\", z.shape)\n",
    "        z = self.latent_in(z)\n",
    "        log(\"latent_in\", z.shape)\n",
    "        return z, skip_connections\n",
    "    \n",
    "    def decode(self, z, skip_connections):\n",
    "        y_hat = self.latent_out(z)\n",
    "        log(\"latent_out\", y_hat.shape)\n",
    "        y_hat = self.unflatten(y_hat)\n",
    "        log(\"unflatten\", y_hat.shape)\n",
    "    \n",
    "        for i, up in enumerate(self.upsample):\n",
    "            y_hat = up(y_hat, skip_connections[-i - 1])\n",
    "            log(\"up\", y_hat.shape)\n",
    "        y_hat = self.output(y_hat)\n",
    "        log(\"output\", y_hat.shape)\n",
    "        return y_hat\n",
    "    \n",
    "    def propagate(self, z):\n",
    "        u, jacobian = self.propagator(z)\n",
    "        return u, jacobian\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z, skip_connections = self.encode(X)\n",
    "        u, jacobian = self.propagator(z)\n",
    "        y_hat = self.decode(z, skip_connections)\n",
    "        return y_hat, self.get_loss(u, jacobian, y_hat, X)\n",
    "    \n",
    "    def parameters_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "class FKLoader:\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = list(range(len(dataset)))\n",
    "        if shuffle:\n",
    "            random.shuffle(self.indices)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         indices = self.indices[idx:idx + self.batch_size]\n",
    "        b = torch.as_tensor(self.dataset[idx:idx + self.batch_size])\n",
    "        return b#torch.stack(self.dataset[idx:idx + self.batch_size])\n",
    "        \n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch = torch.as_tensor(batch)\n",
    "#     c = torch.stack(batch)\n",
    "    log(\"Loading {}\".format(hash(c)))\n",
    "    return c\n",
    "\n",
    "def train(model, loader, optimiser, epochs, frames_in, frames_out, device):\n",
    "    for e in range(epochs):\n",
    "        for b, y in enumerate(loader):\n",
    "            y = y.to(device)\n",
    "            y_in = y[:frames_in]\n",
    "            y_out = y[frames_in:]\n",
    "            \n",
    "            model = model.to(device)\n",
    "            z, skip_connections = model.encode(y)\n",
    "            u, jacobian = model.propagate(z)\n",
    "            y_hat = model.decode(u, skip_connections)\n",
    "            \n",
    "            rec_loss = torch.sqrt(F.mse_loss(y_hat, y, reduction=\"sum\"))\n",
    "            nf_loss = -torch.sum(model.propagator.base_dist.log_prob(u) + jacobian, dim=1).sum()\n",
    "            \n",
    "            loss = rec_loss + nf_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            # log\n",
    "            log_progress(e, b, len(loader), {\"loss\": loss})\n",
    "            idx = random.randint(0, len(y_hat) - 1)\n",
    "            plot_progress(e, y_hat[idx], y[idx], loss)\n",
    "\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    ## HYPERPARAMS\n",
    "    ROOT = \"/media/SSD1/epignatelli/train_dev_set/\"\n",
    "    EPOCHS = 100000\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    INPUT_SIZE = 256\n",
    "    HIDDEN_SIZE = 2048\n",
    "    BATCH_SIZE = 2\n",
    "    IN_FRAMES = 4\n",
    "    OUT_FRAMES = 5\n",
    "    DEBUG = False\n",
    "    \n",
    "    net = UNet([8, 16, 32, 64, 128], HIDDEN_SIZE, INPUT_SIZE, IN_FRAMES, OUT_FRAMES).to(DEVICE)\n",
    "    log(net)\n",
    "    log(net.parameters_count())\n",
    "    filename = glob(ROOT + \"*.hdf5\")[0]\n",
    "    fkset = FkDataset(ROOT, IN_FRAMES, OUT_FRAMES, 1, transforms=t.Compose([Downsample((INPUT_SIZE, INPUT_SIZE))]), squeeze=True)\n",
    "    loader = DataLoader(fkset, num_workers=0, collate_fn=collate_fn, batch_sampler=BatchSampler(RandomSampler(fkset), BATCH_SIZE, True))\n",
    "    optimiser = torch.optim.Adam(net.parameters())\n",
    "  \n",
    "    train(net, loader, optimiser, EPOCHS, IN_FRAMES, OUT_FRAMES, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
