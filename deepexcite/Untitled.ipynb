{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as t\n",
    "import torch.nn.functional as F\n",
    "from dataset import FkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample:\n",
    "    def __init__(self, size, mode=\"bicubic\"):\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return torch.nn.functional.interpolate(x, self.size)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, size=256, h=None, w=None):\n",
    "        self.size = size\n",
    "        self.h = h if h is not None else 1\n",
    "        self.w = w if w is not None else 1\n",
    "        super(Unflatten, self).__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), self.size, self.w, self.h)\n",
    "\n",
    "class Elu(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return nn.functional.elu(x)\n",
    "    \n",
    "class UNetConvBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "\n",
    "        # add convolution 1\n",
    "        self.add_module(\"conv1\",\n",
    "                        nn.Conv2d(in_channels=in_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu1\", nn.ReLU())\n",
    "\n",
    "        # add batchnorm 1\n",
    "        if batch_norm:\n",
    "            self.add_module(\"batchnorm1\", nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # add convolution 2\n",
    "        self.add_module(\"conv2\",\n",
    "                        nn.Conv2d(in_channels=out_channels,\n",
    "                                  out_channels=out_channels,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=int(padding)))\n",
    "        self.add_module(\"relu2\", nn.ReLU())\n",
    "\n",
    "        # add batchnorm 2\n",
    "        if batch_norm:\n",
    "            self.add_module(\"batchnorm2\", nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "\n",
    "        # upsample\n",
    "#         self.up = nn.ConvTranspose2d(in_channels=in_channels,\n",
    "#                                      out_channels=out_channels,\n",
    "#                                      kernel_size=2,\n",
    "#                                      stride=2)\n",
    "        self.up = nn.Upsample(mode=\"bilinear\",\n",
    "                              align_corner=True,\n",
    "                              scale_factor=3)\n",
    "\n",
    "        # add convolutions block\n",
    "        self.conv_block = UNetConvBlock(in_channels=in_channels,\n",
    "                                        out_channels=out_channels,\n",
    "                                        padding=padding,\n",
    "                                        batch_norm=batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, skip_connection):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(skip_connection, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, filters, hidden_dim):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Args:\n",
    "            hyperpara,s (dh.learning.Hyperparams): todo\n",
    "            unet_hyperparams (dh.learning.ConvNetHyperparams): stores the hyperparameters of the downsampling branch of the unet\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        depth = len(filters)\n",
    "        \n",
    "        # downsampling\n",
    "        self.downsample = nn.ModuleList()\n",
    "        in_channels = 3  # v, w, u\n",
    "        for i in range(depth):\n",
    "            print(filters[i])\n",
    "            self.downsample.append(UNetConvBlock(in_channels=in_channels,\n",
    "                                                 out_channels=filters[i],\n",
    "                                                 padding=1,\n",
    "                                                 batch_norm=False))\n",
    "            in_channels = filters[i]\n",
    "        \n",
    "#         # latent\n",
    "#             self.latent_cont = nn.Conv2d(in_channels, in_channels, 1, 1)\n",
    "#             self.flatten = Flatten()\n",
    "#             self.latent_in = nn.Linear(32, hidden_dim)\n",
    "#             self.unflatten = Unflatten(32, 1, 1)\n",
    "#             self.latent_out = nn.Linear(hidden_dim, 32)\n",
    "        \n",
    "        # upsample\n",
    "        self.upsample = nn.ModuleList()\n",
    "        out_filter = [3] + filters\n",
    "        for i in reversed(range(1, depth)):\n",
    "            print(out_filter[i])\n",
    "            self.upsample.append(UNetUpBlock(in_channels=in_channels,\n",
    "                                             out_channels=out_filter[i],\n",
    "                                             padding=1,\n",
    "                                             batch_norm=False))\n",
    "            in_channels = out_filter[i]\n",
    "        return\n",
    "\n",
    "    def forward(self, X, Y=None):\n",
    "        skip_connections = []\n",
    "        for i, down in enumerate(self.downsample):\n",
    "            print(\"down\", X.shape)\n",
    "            X = down(X)\n",
    "            if i != len(self.downsample) - 1:\n",
    "                skip_connections.append(X)\n",
    "                X = F.max_pool2d(X, 4)\n",
    "                \n",
    "#         z = self.flatten(X)\n",
    "#         print(z.shape)\n",
    "#         z = self.latent_in(z)\n",
    "#         print(z.shape)\n",
    "#         z = self.latent_out(z)\n",
    "#         print(z.shape)\n",
    "#         z = self.unflatten(z)\n",
    "#         print(z.shape)\n",
    "\n",
    "        for i, up in enumerate(self.upsample):\n",
    "            print(\"up\", X.shape)\n",
    "            X = up(X, skip_connections[-i - 1])\n",
    "        print(\"output\", X.shape)\n",
    "        return X\n",
    "    \n",
    "    def parameters_count(self):\n",
    "        return sum(p.numel() for p in self.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "64\n",
      "32\n",
      "16\n",
      "8\n",
      "UNet(\n",
      "  (downsample): ModuleList(\n",
      "    (0): UNetConvBlock(\n",
      "      (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (1): UNetConvBlock(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (2): UNetConvBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (3): UNetConvBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (4): UNetConvBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (upsample): ModuleList(\n",
      "    (0): UNetUpBlock(\n",
      "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(4, 4))\n",
      "      (conv_block): UNetConvBlock(\n",
      "        (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): UNetUpBlock(\n",
      "      (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(4, 4))\n",
      "      (conv_block): UNetConvBlock(\n",
      "        (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): UNetUpBlock(\n",
      "      (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(4, 4))\n",
      "      (conv_block): UNetConvBlock(\n",
      "        (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): UNetUpBlock(\n",
      "      (up): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(4, 4))\n",
      "      (conv_block): UNetConvBlock(\n",
      "        (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu1): ReLU()\n",
      "        (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (relu2): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "485808\n",
      "down torch.Size([1, 3, 256, 256])\n",
      "down torch.Size([1, 8, 64, 64])\n",
      "down torch.Size([1, 16, 16, 16])\n",
      "down torch.Size([1, 32, 4, 4])\n",
      "down torch.Size([1, 64, 1, 1])\n",
      "up torch.Size([1, 128, 1, 1])\n",
      "up torch.Size([1, 64, 2, 2])\n",
      "up torch.Size([1, 32, 6, 6])\n",
      "up torch.Size([1, 16, 22, 22])\n",
      "output torch.Size([1, 8, 86, 86])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ## HYPERPARAMS\n",
    "    root = \"/home/ep119/repos/fenton_karma_jax/data/train_dev_set/\"\n",
    "    epochs = 100000\n",
    "    device = torch.device(\"cuda\")\n",
    "    input_size = 256\n",
    "    hidden_dim = 128\n",
    "    loss_coeff = {\n",
    "        \"mse\": 10000.,\n",
    "        \"kld\": 1.,\n",
    "        \"grad\": 0.\n",
    "    }\n",
    "\n",
    "    net = UNet([8, 16, 32, 64, 128], 128)\n",
    "    print(net)\n",
    "    print(net.parameters_count())\n",
    "    fkset = FkDataset(root, 1, 0, 1, transforms=t.Compose([Downsample((input_size, input_size))]), squeeze=True)\n",
    "    net(fkset[0].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
